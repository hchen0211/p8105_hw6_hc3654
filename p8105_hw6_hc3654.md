p8105_hw6_hc3654
================

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   3.5.2     ✔ tibble    3.3.0
    ## ✔ lubridate 1.9.4     ✔ tidyr     1.3.1
    ## ✔ purrr     1.1.0     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(modelr)
library(mgcv)
```

    ## Loading required package: nlme
    ## 
    ## Attaching package: 'nlme'
    ## 
    ## The following object is masked from 'package:dplyr':
    ## 
    ##     collapse
    ## 
    ## This is mgcv 1.9-3. For overview type 'help("mgcv-package")'.

# Problem 1:

``` r
cities_df <- read_csv("https://raw.githubusercontent.com/washingtonpost/data-homicides/refs/heads/master/homicide-data.csv")
```

    ## Rows: 52179 Columns: 12
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (9): uid, victim_last, victim_first, victim_race, victim_age, victim_sex...
    ## dbl (3): reported_date, lat, lon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

## Clean data

``` r
cities_clean_df <- cities_df |> 
  mutate(city_state = paste(city,state,sep = ", "), 
         solve = case_when(
          disposition == "Closed without arrest" ~ 0, 
          disposition == "Open/No arrest" ~ 0,
          disposition == "Closed by arrest" ~ 1)) |> 
  filter(!city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL")) |> 
  filter(victim_race %in% c("White", "Black")) |> 
  mutate(victim_age = as.numeric(victim_age
  )) 
```

    ## Warning: There was 1 warning in `mutate()`.
    ## ℹ In argument: `victim_age = as.numeric(victim_age)`.
    ## Caused by warning:
    ## ! NAs introduced by coercion

## Regression

``` r
fit_log = cities_clean_df |> 
  filter(city_state == "Baltimore, MD") |> 
  glm(solve ~ victim_race + victim_sex + victim_age, data = _, family = binomial()) |> 
  broom::tidy(conf.int = TRUE)

fit_log
```

    ## # A tibble: 4 × 7
    ##   term             estimate std.error statistic  p.value conf.low conf.high
    ##   <chr>               <dbl>     <dbl>     <dbl>    <dbl>    <dbl>     <dbl>
    ## 1 (Intercept)       0.310     0.171        1.81 7.04e- 2  -0.0245  0.648   
    ## 2 victim_raceWhite  0.842     0.175        4.82 1.45e- 6   0.501   1.19    
    ## 3 victim_sexMale   -0.854     0.138       -6.18 6.26e-10  -1.13   -0.584   
    ## 4 victim_age       -0.00673   0.00332     -2.02 4.30e- 2  -0.0133 -0.000246

``` r
fit_log |> 
   filter(term == "victim_sexMale") |> 
  mutate(OR = exp(estimate), OR_lower = exp(conf.low), OR_higher = exp(conf.high)) |>
  select(term, OR, OR_lower, OR_higher) |> 
  knitr::kable(digits = 3)
```

| term           |    OR | OR_lower | OR_higher |
|:---------------|------:|---------:|----------:|
| victim_sexMale | 0.426 |    0.324 |     0.558 |

## For all cities

``` r
odds_ratios_cities <- cities_clean_df |>
  group_by(city_state) |>
  nest() |> 
  mutate(
    model_results = purrr::map(
      .x = data,
      .f = ~ glm(solve ~ victim_race + victim_sex + victim_age, 
                 data = .x, 
                 family = binomial()) |>
             broom::tidy(conf.int = TRUE))) |> 
      unnest(model_results) |> 
filter(term == "victim_sexMale") |> 
  mutate(OR = exp(estimate), OR_lower = exp(conf.low), OR_higher = exp(conf.high)) |>
  select(term, OR, OR_lower, OR_higher) |> 
  arrange(OR)
```

    ## Warning: There were 43 warnings in `mutate()`.
    ## The first warning was:
    ## ℹ In argument: `model_results = purrr::map(...)`.
    ## ℹ In group 1: `city_state = "Albuquerque, NM"`.
    ## Caused by warning:
    ## ! glm.fit: fitted probabilities numerically 0 or 1 occurred
    ## ℹ Run `dplyr::last_dplyr_warnings()` to see the 42 remaining warnings.

    ## Adding missing grouping variables: `city_state`

``` r
odds_ratios_cities |> 
  select(-term)
```

    ## # A tibble: 47 × 4
    ## # Groups:   city_state [47]
    ##    city_state         OR OR_lower OR_higher
    ##    <chr>           <dbl>    <dbl>     <dbl>
    ##  1 New York, NY    0.262    0.133     0.485
    ##  2 Baton Rouge, LA 0.381    0.204     0.684
    ##  3 Omaha, NE       0.382    0.199     0.711
    ##  4 Cincinnati, OH  0.400    0.231     0.667
    ##  5 Chicago, IL     0.410    0.336     0.501
    ##  6 Long Beach, CA  0.410    0.143     1.02 
    ##  7 San Diego, CA   0.413    0.191     0.830
    ##  8 Baltimore, MD   0.426    0.324     0.558
    ##  9 Pittsburgh, PA  0.431    0.263     0.696
    ## 10 Denver, CO      0.479    0.233     0.962
    ## # ℹ 37 more rows

``` r
odds_ratios_cities|> 
ggplot(aes(x = OR, y = fct_reorder(city_state, OR)))+
  geom_point()+
  geom_errorbarh(aes(xmin = OR_lower, xmax = OR_higher), 
                 height = 0.2, 
                 color = "darkgray")
```

![](p8105_hw6_hc3654_files/figure-gfm/unnamed-chunk-6-1.png)<!-- -->
\### Comment:

The plot reveals that the adjusted Odds Ratio (OR) is less than 1 for
the majority of cities, indicating a prevailing pattern where female
victims’ homicides have a higher solved advantage (odds) than those of
male victims.

However, a crucial finding is that the confidence interval for the OR
includes 1 for most cities. This means we lack sufficient statistical
evidence to claim a significant gender difference in clearance rates in
the majority of locations.

The results highlight two extremes: New York, NY, exhibits the strongest
disparity (OR lowest), where the difference in solved odds between male
and female victims is most pronounced and statistically significant.
Conversely, Albuquerque, NM, holds the highest OR, suggesting male
victims’ cases are either equally or more likely to be solved there,
it’s not significant due to including the 1.0.

The clustering of most OR estimates between 0.5 and 1.0 confirms that
while a bias exists, the magnitude of the disadvantage for male victims
is generally moderate to significant across the cities, driving the
overall conclusion that female victims’ homicides are generally more
likely to be solved across the dataset.

# Problem 2:

``` r
library(p8105.datasets)
data("weather_df")
```

``` r
weather_cleaned_df = weather_df |> 
  na.omit()

fit_t <- lm(tmax ~ tmin + prcp, data = weather_cleaned_df) 

fit_t |> 
  broom::tidy() |> 
  filter(term == "tmin"| term == "prcp") |> 
  select(term, estimate) |> 
  pivot_wider(
    names_from = term,
    values_from = estimate
  ) |> 
  mutate(ratio = tmin/prcp) |> 
  select(ratio)
```

    ## # A tibble: 1 × 1
    ##   ratio
    ##   <dbl>
    ## 1 -182.

``` r
fit_t |> 
  broom::glance() |> 
  select(r.squared)
```

    ## # A tibble: 1 × 1
    ##   r.squared
    ##       <dbl>
    ## 1     0.941

``` r
set.seed(1)

fit_bootstrap = 
  weather_cleaned_df |> 
  bootstrap(n = 5000) |> 
  mutate(
    df = map(strap, as_tibble),
    fits = map(df, \(df) lm(tmax ~ tmin + prcp, data = df))
  ) |> 
  mutate(r_squared = map_dbl(fits, 
                        .f = ~ broom::glance(.x) |> pull(r.squared)
    )) |>
  mutate(
      beta_ratio = map_dbl(fits, 
                         .f = ~ broom::tidy(.x) |> 
                           filter(term %in% c("tmin", "prcp")) |> 
                           select(term, estimate) |> 
                           pivot_wider(names_from = term, values_from = estimate) |> 
                           mutate(ratio = tmin / prcp) |>
                           pull(ratio))) |> 
  select(.id, r_squared, beta_ratio)
```

### For R^2

``` r
ggplot(fit_bootstrap, aes(x = r_squared)) +
  geom_density(fill = "lightblue", alpha = 0.6) +
  labs(title = "Bootstrap Distribution of R-squared", x = "R^2 Estimate") +
  theme_minimal()
```

![](p8105_hw6_hc3654_files/figure-gfm/unnamed-chunk-10-1.png)<!-- -->

``` r
fit_bootstrap |>
  summarize(
    R2_lower = quantile(r_squared, 0.025),
    R2_upper = quantile(r_squared, 0.975)
  ) |> 
    knitr::kable(digits = 3)
```

| R2_lower | R2_upper |
|---------:|---------:|
|    0.934 |    0.947 |

### For Beta(1) / Beta(2)

``` r
ggplot(fit_bootstrap, aes(x = beta_ratio)) +
  geom_density(fill = "lightblue", alpha = 0.6) +
  labs(title = "Bootstrap Distribution of R-squared", x = "R^2 Estimate") +
  theme_minimal()
```

![](p8105_hw6_hc3654_files/figure-gfm/unnamed-chunk-11-1.png)<!-- -->

``` r
fit_bootstrap |>
  summarize(
    Ratio_lower = quantile(beta_ratio, 0.025, na.rm = TRUE),
    Ratio_upper = quantile(beta_ratio, 0.975, na.rm = TRUE)
  ) |> 
    knitr::kable(digits = 3)
```

| Ratio_lower | Ratio_upper |
|------------:|------------:|
|    -274.795 |    -125.484 |

# Problem 3:

``` r
baby_df_cleaned = read.csv("birthweight.csv") |> 
  janitor::clean_names() |> 
  mutate(babysex = as.factor(babysex), frace = as.factor(frace), malform = as.factor(malform), mrace = as.factor(mrace), parity = as.factor(parity), smoken = as.factor(smoken)) |> 
  drop_na()


my_mod <- lm(bwt ~ mheight + delwt + mrace, data = baby_df_cleaned) 


baby_df_cleaned|> 
  add_predictions(my_mod) |> 
  add_residuals(my_mod) |> 
  ggplot(aes(x = pred, y = resid))+
  geom_point(alpha = 0.5)+
  geom_hline(yintercept = 0, linetype = "dashed", color = "red")+
  labs(title = "residuals vs. predictions",
       subtitle = "model: bwt ~ mheight + delwt + mrace ",
       x = "predictions",
       y = "residuals") +
  theme_bw()
```

![](p8105_hw6_hc3654_files/figure-gfm/unnamed-chunk-12-1.png)<!-- -->

``` r
# Other two models
main_effs_mod = lm(bwt ~ blength + gaweeks, data = baby_df_cleaned)

three_ways_mod = lm(bwt ~ bhead + blength+ babysex, data = baby_df_cleaned)
```

``` r
# Comparison 

cv_df = 
  modelr::crossv_mc(baby_df_cleaned, n = 100) |> 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)
  )

cv_df_fits <- cv_df |>
  mutate(
    my_mod_fit = map(train, \(df) lm(my_mod, data = df)),
    main_effs_mod_fit = map(train, \(df) lm(main_effs_mod, data = df)),
    three_ways_mod_fit = map(train, \(df) lm(three_ways_mod, data = df))
  ) |> 
  mutate(
    rmse_my_mod = map2_dbl(my_mod_fit, test, modelr::rmse),
    rmse_main_effs = map2_dbl(main_effs_mod_fit, test, modelr::rmse),
    rmse_three_ways = map2_dbl(three_ways_mod_fit, test, modelr::rmse)
  )


cv_df_fits |>
  select(starts_with("rmse_")) |>
  pivot_longer(everything(), names_to = "model", values_to = "rmse") |>
  group_by(model) |>
  summarize(
    rmse = mean(rmse),
    .groups = "drop"
  ) 
```

    ## # A tibble: 3 × 2
    ##   model            rmse
    ##   <chr>           <dbl>
    ## 1 rmse_main_effs   333.
    ## 2 rmse_my_mod      466.
    ## 3 rmse_three_ways  289.

``` r
cv_df_fits |> 
  select(rmse_main_effs, rmse_three_ways, rmse_my_mod) |> 
  pivot_longer(
    everything(),
    names_to = "mod",
    values_to = "rmse",
    names_prefix = "rmse_"
  ) |> 
  ggplot(aes(x = mod, y = rmse, fill = mod))+
  geom_violin()
```

![](p8105_hw6_hc3654_files/figure-gfm/unnamed-chunk-14-1.png)<!-- -->
